---
title: "Solving the Black Box Problem: A Normative Framework for Explainable Artificial Intelligence"
authors:
- carlos-zednik
author_notes:
- ''
- ''
date: "2021-06-01T00:00:00Z"
doi: "10.1007/s13347-019-00382-7"

# Schedule page publish date (NOT publication's date).
publishDate: "2022-03-22T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["2"]

# Publication name and optional abbreviated publication name.
publication: "*Philosophy & Technology*"
publication_short: ""

abstract: 'Many of the computing systems programmed using Machine Learning are *opaque*: it is difficult to know why they do what they do or how they work. *Explainable Artificial Intelligence* aims to develop analytic techniques that render opaque computing systems transparent, but lacks a normative framework with which to evaluate these techniques’ explanatory successes. The aim of the present discussion is to develop such a framework, paying particular attention to different stakeholders’ distinct explanatory requirements. Building on an analysis of "opacity" from philosophy of science, this framework is modeled after accounts of explanation in cognitive science. The framework distinguishes between the explanation-seeking questions that are likely to be asked by different stakeholders, and specifies the general ways in which these questions should be answered so as to allow these stakeholders to perform their roles in the *Machine Learning ecosystem*. By applying the normative framework to recently developed techniques such as *input heatmapping*, *feature-detector visualization*, and *diagnostic classification*, it is possible to determine whether and to what extent techniques from Explainable Artificial Intelligence can be used to render opaque computing systems transparent and, thus, whether they can be used to solve the *Black Box Problem*.'

# Summary. An optional shortened abstract.
summary:

tags:
- 'explainability'
- 'black box problem'
- 'epistemic opacity'
- 'artificial intelligence'
- 'levels of analysis'
- 'machine learning'
- 'scientific explanation'
featured: false

# links:
# - name: ""
#   url: ""
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
#image:
 # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/jdD8gXaTZsc)'
 # focal_point: ""
 # preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: [trustworthy-ai]

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides:
---

