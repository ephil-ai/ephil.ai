---
title: "Ethical Issues with Artificial Ethics Assistants"
authors:
- elizabeth-oneill
- Michal Klincewicz
- Michiel Kemmer
author_notes:
- ''
- ''
date: "2022-10-20T00:00:00Z"
doi: "10.1093/oxfordhb/9780198857815.013.17
"

# Schedule page publish date (NOT publication's date).
publishDate: "2023-09-28T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["6"]

# Publication name and optional abbreviated publication name.
publication: "*The Oxford Handbook of Digital Ethics*"
publication_short: ""

abstract: "This chapter examines the possibility of using artificial intelligence (AI) technologies to improve human moral reasoning and decision-making. The authors characterize such technologies as artificial ethics assistants (AEAs). The authors focus on just one part of the AI-aided moral improvement question: the case of the individual who wants to improve their morality, where what constitutes an improvement is evaluated by the individual’s own values. The authors distinguish three broad areas in which an individual might think their own moral reasoning and decision-making could be improved: one’s actions, character, or other attributes fall short of one’s values and moral beliefs; one sometimes misjudges or is uncertain about what the right thing to do is, given one’s values; or one is uncertain about some fundamental moral questions or recognizes a possibility that some of one’s core moral beliefs and values are mistaken. The authors sketch why one might think AI tools could be used to support moral improvement in those areas and distinguish two types of assistance: preparatory assistance, including advice and training supplied in advance of moral deliberation, and on-the-spot assistance, including on-the-spot advice and facilitation of moral functioning over the course of moral deliberation. Then, the authors turn to ethical issues that AEAs might raise, looking in particular at three under-appreciated problems posed by the use of AI for moral self-improvement: namely, reliance on sensitive moral data, the inescapability of outside influences on AEAs, and AEA usage prompting the user to adopt beliefs and make decisions without adequate reasons."

# Summary. An optional shortened abstract.
summary:

tags:
- artificial intelligence
- artificial ethics assistant
- artificial ethics advisor
- moral cognition
- moral enhancement
- moral decision-making
featured: false

# links:
# - name: ""
#   url: ""
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
#image:
 # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/jdD8gXaTZsc)'
 # focal_point: ""
 # preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: [trustworthy-ai]

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides:
---

