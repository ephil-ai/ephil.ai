---
title: AI & Responsibility
summary: 'Responsibility, meaningful human control and justice in AI' [(read more)](/project/responsibility)'
date: "2021-12-01T00:00:00Z"
profile: false
show_date: false

# For order in list 
weight: 10

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, place an image named `featured.jpg/png` in your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
# Set `preview_only` to `true` to just use the image for thumbnails.
image:
 caption: "Image created with [DALL·E by OpenAI](https://openai.com/dall-e-3)"
 placement: 1
 focal_point: Smart
 preview_only: false


links:
#- icon: twitter
 # icon_pack: fab
 # name: Follow
 # url: https://twitter.com/georgecushen
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ''
---
The development of AI has raised new attention to the question of responsibility for technological development. Who should be held responsible when AI systems harm persons and society, and how to develop AI responsibly are two recurring questions in public debates and academic research in AI ethics. Responsibility is also crucially connected to human control and justice. As for control: For human actors to remain responsible for the AI behaviour (i.e to avoid “responsibility gaps”), they must maintain some form of “meaningful human control” over AI, but what does that mean precisely and how to achieve it in different (critical) domains, e.g. healthcare, defence, transportation, without losing the potential many benefit of task delegation to artificial systems with autonomous capabilities? As for justice, people may maintain control and responsibility over AI systems only if they are given the capacity and opportunity to do so, but this crucially depends on them not being socially excluded, oppressed, or discriminated, so meaningful human control over AI also requires social justice. Also, the responsible development of AI seems to require some form of “design justice”, that is people whose lives will be affected by AI must be able to effectively contribute to the reflection over- and development of new AI technologies. This also includes the issue of climate justice. As it were, responsible AI development must also be democratic. This lab will connect researchers and stakeholders interested in developing theories and practices for responsible AI, meaningful human control, and just and democratic AI development.  

## Research Questions
- Who should take moral responsibility for the development and use of AI, and what does that mean, in theory and practice?
- What is meaningful human control of AI system, to what extent is it desirable and how to achieve it in different domains of application?
- How can social justice support control and responsibility over AI, and how can AI systems be more just, also in the light of the climate crisis (climate justice)?
- What is design justice, and how can the AI design process be more democratic?  


## Activities
-

## Associated Researchers

- Filippo Santoni de Sio 
- Michela Ghezzi
- Laila Wegner
