---
title: Trustworthy AI
summary: 'Transparency is a cornerstone of the responsible use and development of artificial intelligence. Unfortunately, many state-of-the-art AI systems are notoriously opaque: it is difficult to know what these systems are actually doing, why they do what they do, and how they do it. [(read more)](/project/opacity-ml)'
date: "2021-12-01T00:00:00Z"
profile: false
show_date: false

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, place an image named `featured.jpg/png` in your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
# Set `preview_only` to `true` to just use the image for thumbnails.
image:
 caption: "Image created with [DALL·E by OpenAI](https://openai.com/dall-e-2/) (prompt: an opaque deep learning model)"
 placement: 1
 focal_point: Smart
 preview_only: false


links:
#- icon: twitter
 # icon_pack: fab
 # name: Follow
 # url: https://twitter.com/georgecushen
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ''
---

Transparency is a cornerstone of the responsible use and development of artificial intelligence. Unfortunately, many state-of-the-art AI systems are notoriously opaque: it is difficult to know what these systems are actually doing, why they do what they do, and how they do it. The Explainable AI research program is dedicated to the challenge of rendering opaque AI systems transparent. However, questions remain about what exactly opacity is, what kinds of transparency are required when and by whom, and how such transparency can actually be achieved.

ECPAI researchers are engaged in the project of defining normative constraints on Explainable AI, and actively collaborate with industry and research to develop methods with which to explain the behavior of opaque AI systems. To this end, they study typical use-cases of Explainable AI, evaluate the possibilities and limits of current explanatory practices, and participate in regulatory efforts to guide their development and use.

## Valorization

Carlos Zednik and Yeji Streppel haved helped write a preliminary standard for explainable AI (XAI) called [DIN SPEC 92001-3]((https://www.beuth.de/en/technical-rule/din-spec-92001-3/369799101)). This standard reflects the current state of XAI research and proposes a process model for developing trustworthy XAI systems that could be used to ensure the quality of machine learning systems. The proposed workflow includes formally specifying use-case-specific XAI problems and formally verifying the resulting solutions.


## Associated Researchers

- Carlos Zednik
- Céline Budding
- Emily Sullivan (Area Lead)
- Philippe Verreault-Julien
- Yeji Streppel