---
title: AI and Deception Reading Group
summary: 'As social robots become more prevalent, some worry about the nature of the relationship between humans and social robots.'
authors: [guido-lohr, michael-dale]
tags: [deception, robots, emotions]
categories: []
date: 2022-10-11T11:53:39+02:00
show_date: false

type: page

reading_time: false

featured: true

profile: true
# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
# Set `preview_only` to `true` to just use the image for thumbnails.
image:
 caption: "Image created with [DALL·E by OpenAI](https://openai.com/dall-e-2/) (prompt: a photo of a robot that looks like dr evil holding a persian cat)"
 placement: 1
 focal_point: Smart
 preview_only: false

projects: [social-robots-ai]

links:
#- icon: twitter
 # icon_pack: fab
 # name: Follow
 # url: https://twitter.com/georgecushen
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ''
---

As social robots become more prevalent, some worry about the nature of the relationship between humans and social robots. For instance, humans have a tendency to attribute complex cognitive and emotional capacities to objects (which often leads to them empathizing with such objects). This tendency could be used to deceive humans into thinking that robots have more cognitive and emotional capacities than they actually do. In what instances does such deception occur? Is it morally problematic? What does this mean for relationships (and friendships) between humans and, say, care robots or sex robots?

Moreover, there has recently been some work on the question of whether robots themselves can lie to us or in other ways deceive us, or whether they can only be used by other humans to do so. What does it mean for anyone to deceive us and can this be applied to robots? What requirements do chatbots for example have to meet, such that it would be possible for them to mislead or trick us?

**Date and Time of first meeting:** October 27 at 4 PM CEST, online.

Contact [Michael Dale](mailto:m.t.dale@tue.nl) or [Guido Löhr](mailto:g.lohr@tue.nl) to join the group or receive updates.